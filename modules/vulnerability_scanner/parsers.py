# -*- coding: utf-8 -*-
"""
Dependency file parsers for multiple ecosystems
"""
import os
import re
import json
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import List
from .models import Dependency


class DependencyParser:
    """Base parser for dependency files"""
    
    @staticmethod
    def parse_requirements_txt(file_path: str) -> List[Dependency]:
        """
        Parse Python requirements.txt file
        Supports: package==version, package>=version, package
        """
        dependencies = []
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    
                    # Skip empty lines and comments
                    if not line or line.startswith('#'):
                        continue
                    
                    # Skip -e (editable) and URLs
                    if line.startswith('-e') or line.startswith('http'):
                        continue
                    
                    # Extract package and version
                    # Supports: package==1.0.0, package>=1.0.0, package~=1.0.0
                    match = re.match(r'^([a-zA-Z0-9._-]+)([=><~!]+)(.+)$', line)
                    if match:
                        package = match.group(1).strip()
                        version = match.group(3).strip()
                        
                        # Clean version (remove extras like [dev])
                        version = re.sub(r'\[.*?\]', '', version).strip()
                        
                        dependencies.append(Dependency(
                            package=package,
                            version=version,
                            ecosystem='PyPI',
                            source_file=file_path
                        ))
                    else:
                        # Package without version specified
                        package = line.split('[')[0].strip()
                        if package:
                            dependencies.append(Dependency(
                                package=package,
                                version='latest',
                                ecosystem='PyPI',
                                source_file=file_path
                            ))
        
        except Exception as e:
            print(f"   ⚠️  Error parsing {file_path}: {e}")
        
        return dependencies
    
    @staticmethod
    def parse_package_json(file_path: str) -> List[Dependency]:
        """
        Parse Node.js package.json file
        Extracts dependencies and devDependencies
        """
        dependencies = []
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                data = json.load(f)
            
            # Parse dependencies and devDependencies
            for section in ['dependencies', 'devDependencies', 'peerDependencies']:
                if section in data and isinstance(data[section], dict):
                    for package, version in data[section].items():
                        # Clean version: remove ^, ~, >=, etc.
                        clean_version = re.sub(r'^[\^~>=<]+', '', version).strip()
                        
                        # Handle version ranges (take first version)
                        if ' ' in clean_version:
                            clean_version = clean_version.split()[0]
                        
                        dependencies.append(Dependency(
                            package=package,
                            version=clean_version,
                            ecosystem='npm',
                            source_file=file_path
                        ))
        
        except json.JSONDecodeError:
            print(f"   ⚠️  Invalid JSON in {file_path}")
        except Exception as e:
            print(f"   ⚠️  Error parsing {file_path}: {e}")
        
        return dependencies
    
    @staticmethod
    def parse_package_lock_json(file_path: str) -> List[Dependency]:
        """
        Parse Node.js package-lock.json for exact versions
        """
        dependencies = []
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                data = json.load(f)
            
            # package-lock.json v1 format
            if 'dependencies' in data:
                for package, info in data['dependencies'].items():
                    if 'version' in info:
                        dependencies.append(Dependency(
                            package=package,
                            version=info['version'],
                            ecosystem='npm',
                            source_file=file_path
                        ))
            
            # package-lock.json v2/v3 format
            elif 'packages' in data:
                for package_path, info in data['packages'].items():
                    if package_path and 'version' in info:
                        # Extract package name from path
                        package = package_path.split('node_modules/')[-1]
                        dependencies.append(Dependency(
                            package=package,
                            version=info['version'],
                            ecosystem='npm',
                            source_file=file_path
                        ))
        
        except json.JSONDecodeError:
            print(f"   ⚠️  Invalid JSON in {file_path}")
        except Exception as e:
            print(f"   ⚠️  Error parsing {file_path}: {e}")
        
        return dependencies
    
    @staticmethod
    def parse_pom_xml(file_path: str) -> List[Dependency]:
        """
        Parse Maven pom.xml file
        Extracts dependencies with groupId, artifactId, and version
        """
        dependencies = []
        
        try:
            tree = ET.parse(file_path)
            root = tree.getroot()
            
            # Handle XML namespaces
            ns = {'maven': 'http://maven.apache.org/POM/4.0.0'}
            if root.tag.startswith('{'):
                ns_match = re.match(r'\{(.+?)\}', root.tag)
                if ns_match:
                    ns['maven'] = ns_match.group(1)
            
            # Find all dependency elements
            for dep in root.findall('.//maven:dependency', ns):
                artifact_elem = dep.find('maven:artifactId', ns)
                version_elem = dep.find('maven:version', ns)
                group_elem = dep.find('maven:groupId', ns)
                
                if artifact_elem is not None:
                    artifact_id = artifact_elem.text
                    version = version_elem.text if version_elem is not None else 'unknown'
                    group_id = group_elem.text if group_elem is not None else ''
                    
                    # Clean version (remove ${} variables)
                    if '${' in version:
                        version = 'variable'
                    
                    # Use full name: groupId:artifactId
                    package = f"{group_id}:{artifact_id}" if group_id else artifact_id
                    
                    dependencies.append(Dependency(
                        package=package,
                        version=version,
                        ecosystem='Maven',
                        source_file=file_path
                    ))
        
        except ET.ParseError:
            print(f"   ⚠️  Invalid XML in {file_path}")
        except Exception as e:
            print(f"   ⚠️  Error parsing {file_path}: {e}")
        
        return dependencies
    
    @staticmethod
    def parse_gradle(file_path: str) -> List[Dependency]:
        """
        Parse Gradle build.gradle file (basic regex parsing)
        """
        dependencies = []
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # Match dependency declarations
            # implementation 'group:artifact:version'
            # compile 'group:artifact:version'
            patterns = [
                r"(?:implementation|compile|api|testImplementation)\s+['\"]([^:]+):([^:]+):([^'\"]+)['\"]",
                r"(?:implementation|compile|api|testImplementation)\s*\(\s*['\"]([^:]+):([^:]+):([^'\"]+)['\"]\s*\)"
            ]
            
            for pattern in patterns:
                matches = re.finditer(pattern, content)
                for match in matches:
                    group_id = match.group(1)
                    artifact_id = match.group(2)
                    version = match.group(3)
                    
                    package = f"{group_id}:{artifact_id}"
                    
                    dependencies.append(Dependency(
                        package=package,
                        version=version,
                        ecosystem='Maven',
                        source_file=file_path
                    ))
        
        except Exception as e:
            print(f"   ⚠️  Error parsing {file_path}: {e}")
        
        return dependencies
    
    @staticmethod
    def discover_dependencies(project_path: str) -> List[Dependency]:
        """
        Discover and parse all dependency files in a project
        """
        all_dependencies = []
        dependency_files = {
            'requirements.txt': DependencyParser.parse_requirements_txt,
            'package.json': DependencyParser.parse_package_json,
            'package-lock.json': DependencyParser.parse_package_lock_json,
            'pom.xml': DependencyParser.parse_pom_xml,
            'build.gradle': DependencyParser.parse_gradle,
        }
        
        print(f"\n[*] Discovering dependency files in: {project_path}")
        
        # Walk through project directory
        for root, dirs, files in os.walk(project_path):
            # Skip common non-source directories
            dirs[:] = [d for d in dirs if d not in [
                '.git', '.svn', 'node_modules', '__pycache__', 
                'venv', 'env', '.venv', 'build', 'dist', 'target',
                '.idea', '.vscode', 'output'
            ]]
            
            for file in files:
                if file in dependency_files:
                    file_path = os.path.join(root, file)
                    print(f"   → Found: {file_path}")
                    
                    parser = dependency_files[file]
                    deps = parser(file_path)
                    
                    if deps:
                        print(f"      ✓ Extracted {len(deps)} dependencies")
                        all_dependencies.extend(deps)
        
        # Remove duplicates (same package+version from multiple files)
        seen = set()
        unique_deps = []
        for dep in all_dependencies:
            key = f"{dep.ecosystem}:{dep.package}:{dep.version}"
            if key not in seen:
                seen.add(key)
                unique_deps.append(dep)
        
        print(f"\n[+] Total unique dependencies found: {len(unique_deps)}\n")
        
        return unique_deps






